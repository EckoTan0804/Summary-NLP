{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-Gram Language Model (TL;DR)\n",
    "\n",
    "Language models \n",
    "\n",
    "- offer a way to assign a probability to a sentence or other sequence of words, and to predict a word from preceding words.\n",
    "  - $P(w|h)$: Probability of word $w$ given history $h$\n",
    "\n",
    "n-gram model:\n",
    "\n",
    "- estimate words from a fixed window of previous words\n",
    "  $$\n",
    "  P\\left(w_{n} | w_{1}^{n-1}\\right) \\approx P\\left(w_{n} | w_{n-N+1}^{n-1}\\right)\n",
    "  $$\n",
    "\n",
    "- n-gram probabilities can be estimated by counting in a corpus and normalizing (**MLE**)\n",
    "  $$\n",
    "  P\\left(w_{n} | w_{n-N+1}^{n-1}\\right)=\\frac{C\\left(w_{n-N+1}^{n-1} w_{n}\\right)}{C\\left(w_{n-N+1}^{n-1}\\right)}\n",
    "  $$\n",
    "\n",
    "- Evaluation\n",
    "\n",
    "  - Extrinsically in some task (expensive!)\n",
    "\n",
    "  - Instrinsically using **perplexity**\n",
    "\n",
    "    - perplexity of a test set according to a language model: the geometric mean of the inverse test set probability computed by the model.\n",
    "      $$\n",
    "      \\begin{array}{ll}\n",
    "      \\operatorname{PP}(W) &=P\\left(w_{1} w_{2} \\ldots w_{N}\\right)^{-\\frac{1}{N}} \\\\\n",
    "      &=\\sqrt[N]{\\frac{1}{P\\left(w_{1} w_{2} \\ldots w_{N}\\right)}} \\\\\n",
    "      &\\overset{\\text{chain rule}}{=} \\sqrt[N]{\\displaystyle\\prod_{i=1}^{N} \\frac{1}{P\\left(w_{i} | w_{1} \\ldots w_{i-1}\\right)}}\n",
    "      \\end{array}\n",
    "      $$\n",
    "\n",
    "Smoothing: provide a more sophisticated way to estimate the probability of n-grams\n",
    "\n",
    "- Laplace (Add-one) smmothing\n",
    "  $$\n",
    "  P_{\\text {Laplace}}\\left(w_{i}\\right)=\\frac{c_{i}+1}{N+V}\n",
    "  $$\n",
    "\n",
    "  - $V$: Number of words in the vocabulary\n",
    "\n",
    "- Add-k smoothing\n",
    "  $$\n",
    "  P_{\\mathrm{Add}-\\mathrm{k}}^{*}\\left(w_{n} | w_{n-1}\\right)=\\frac{C\\left(w_{n-1} w_{n}\\right)+k}{C\\left(w_{n-1}\\right)+k V}\n",
    "  $$\n",
    "\n",
    "- Backoff or interpolation\n",
    "\n",
    "  - Rely on lower-order n-gram counts\n",
    "\n",
    "- Kneser-Ney smoothing\n",
    "\n",
    "  - makes use of the probability of a word being a novel continuation\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
